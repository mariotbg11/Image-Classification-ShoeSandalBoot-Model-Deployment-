# -*- coding: utf-8 -*-
"""Project 3 Image Classification Model ShoeSandalBoot Deployment Mario Christofell.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19Vvwc2hKow3WcT_ukNyUzP-58z765ciT

# Mario Christofell L.Tobing

Project 3 Dicoding Modul Belajar Pengembangan Machine Learning

*   Image Classification Model Deployment
*   Dataset from Kaggle : Shoe vs Sandal vs Boot Image Dataset (15K Images) (https://www.kaggle.com/datasets/hasibalmuzdadid/shoe-vs-sandal-vs-boot-dataset-15k-images)

# Import Library
"""

import os
import shutil
import zipfile
import matplotlib.pyplot as plt
import splitfolders
import pathlib
import tensorflow as tf
from tensorflow.keras.models import Sequential
from keras.layers import Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import EarlyStopping

"""# Install & Upload Dataset Kaggle"""

# install kaggle package
!pip install -q kaggle

# upload kaggle.json
from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

!kaggle datasets download -d hasibalmuzdadid/shoe-vs-sandal-vs-boot-dataset-15k-images -p /content/img/ --unzip

"""# Split Folder"""

local_dir = '/img/Shoe vs Sandal vs Boot Dataset/' # direktori pertama
if ('datast' in os.listdir(local_dir)):
  shutil.rmtree(os.path.join(local_dir, 'datast'))

splitfolders.ratio('/img/Shoe vs Sandal vs Boot Dataset/', output ='/img/Shoe vs Sandal vs Boot Dataset/datast',
                    seed=None, ratio=(.8,.2)) # pembagian untuk ukuran data training sebesar 80% dan validation 20%

# Direktori masing -masing jenis gambar rock, paper, scissors
boot = os.path.join('/img/Shoe vs Sandal vs Boot Dataset/Boot') # direktori jenis gambar Boct
sandal = os.path.join('/img/Shoe vs Sandal vs Boot Dataset/Sandal') # direktori jenis gambar Sandal
sshoe = os.path.join('/img/Shoe vs Sandal vs Boot Dataset/Shoe') # direktori jenis gambar Shoe

# Direktori pada Data Training dari tiap jenis gambar (80%)
boot_train = os.path.join('/img/Shoe vs Sandal vs Boot Dataset/datast/train/Boot') # banyaknya jenis gambar rock pada data training
sandal_train = os.path.join('/img/Shoe vs Sandal vs Boot Dataset/datast/train/Sandal') # banyaknya jenis gambar paper pada data training
shoe_train = os.path.join('/img/Shoe vs Sandal vs Boot Dataset/datast/train/Shoe') # banyaknya jenis gambar scissors pada data training

# Direktori pada Data Validation dari tiap jenis gambar (20%)
boot_val = os.path.join('/img/Shoe vs Sandal vs Boot Dataset/datast/val/Boot') # banyaknya jenis gambar rock pada data validation
sandal_val = os.path.join('/img/Shoe vs Sandal vs Boot Dataset/datast/val/Sandal') # banyaknya jenis gambar paper pada data validation 
shoe_val = os.path.join('/img/Shoe vs Sandal vs Boot Dataset/datast/val/Shoe') # banyaknya jenis gambar scissors pada data validation

"""# Augmentasi with ImgaeDataGenerator"""

train_dir = "/img/Shoe vs Sandal vs Boot Dataset/datast/train"
train_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=20,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    fill_mode = 'nearest')

val_dir = "/img/Shoe vs Sandal vs Boot Dataset/datast/val"
val_datagen = ImageDataGenerator(
                    rescale=1./255)

train_generator = train_datagen.flow_from_directory(
	train_dir, # direktori data training
	target_size=(150,150), # ukuran reolusi gambar diubah menjadi 150x150 pixel
  batch_size=10,
	class_mode='categorical' # klasifikasi yang akan dilakukan adalah multi kelas maka menggunakan categorical
)

validation_generator = val_datagen.flow_from_directory(
	val_dir, # direktori data validasi
	target_size=(150,150), # ukuran reolusi gambar diubah menjadi 150x150 pixel
  batch_size=10,
	class_mode='categorical' # klasifikasi yang akan dilakukan adalah multi kelas maka menggunakan categorcial
)

"""# Model"""

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)), # konvulusi 1
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), # konvulusi 2
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'), # konvulusi 3
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'), # konvulusi 4
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax') # menggunakan fungsi aktivasi 'softmax' karena klasifikasi yang dilakukan merupakan multi kelas 
])

model.summary()

"""# Callback Function"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.9 and logs.get('val_accuracy')>0.9):
      print("\nThe accuracy has reached > 90%!")
      self.model.stop_training = True

callbacks = myCallback()

"""# Train Model"""

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

history = model.fit(
      train_generator,
      steps_per_epoch=10,
      batch_size=128,
      epochs=30,
      validation_data=validation_generator,
      validation_steps=5,
      verbose=1,
      callbacks=[callbacks])

"""# Visualization Plot Accuracy & Loss Model"""

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

"""# Save Model to TF-Lite"""

# Menyimpan model dalam format SavedModel
export_dir = 'saved_model/'
tf.saved_model.save(model, export_dir)

# Convert SavedModel menjadiÂ vegs.tflite
converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()

tflite_model_file = pathlib.Path('shoe.tflite')
tflite_model_file.write_bytes(tflite_model)